#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Gradient compuations
\end_layout

\begin_layout Section
Optimization problem
\end_layout

\begin_layout Standard
Let us consider the following optimization problem
\begin_inset Formula 
\begin{align*}
\arg\min_{A\geq0,P\geq0} & \mathcal{L}(A,P)\\
\text{where} & \mathcal{L}(A,P)=-\langle X,\log(GPA)\rangle+\langle\mathbf{1}^{\ell,p},GPA\rangle
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Gradient computations
\end_layout

\begin_layout Standard
Let us first notice that for
\begin_inset Formula 
\[
f(\Lambda)=\sum_{i,j}X_{ij}\log\left(\Lambda_{ij}\right)=\langle X,\log(\Lambda)\rangle
\]

\end_inset


\begin_inset Formula 
\[
\frac{\partial f}{\partial\Lambda_{i,j}}=\frac{X_{ij}}{\Lambda_{ij}}\hspace{1em}\nabla_{\Lambda}f_{2}=X\oslash\Lambda\neq X\Lambda^{-1}
\]

\end_inset

Here the symbol 
\begin_inset Formula $\oslash$
\end_inset

 means the elementwise division.
 So finally we have:
\begin_inset Formula 
\[
\mathcal{L}(A,P)=-\langle X,\log(GPA)\rangle+\langle\mathbf{1}^{\ell,p},GPA\rangle
\]

\end_inset


\begin_inset Formula 
\[
\nabla_{A}\mathcal{L}=-P^{T}G^{T}\left(X\oslash GPA\right)+P^{T}G^{T}\mathbf{\mathbf{1}^{\ell,p}}
\]

\end_inset


\begin_inset Formula 
\[
\nabla_{P}\mathcal{L}=-G^{T}\left(X\oslash GPA\right)A^{T}+G^{T}\mathbf{1}^{\ell,p}A^{T}
\]

\end_inset

Note that if we add a small term 
\begin_inset Formula $\mathbb{\eta}$
\end_inset

 in the loss: 
\begin_inset Formula $\mathcal{L}^{\prime}(A,P)=-\langle X,\log(GPA+\mathbb{\eta})\rangle+\langle\mathbf{1}^{\ell,p},GPA\rangle$
\end_inset

, we obtain
\begin_inset Formula 
\[
\nabla_{A}\mathcal{L^{\prime}}=-P^{T}G^{T}\left(X\oslash\left(GPA+\mathbb{\eta}\right)\right)+P^{T}G^{T}\mathbf{1}^{\ell,p}
\]

\end_inset


\begin_inset Formula 
\[
\nabla_{P}\mathcal{L}^{\prime}=-G^{T}\left(X\oslash\left(GPA+\mathbb{\eta}\right)\right)A^{T}+G^{T}\mathbf{1}^{\ell,p}A^{T}
\]

\end_inset


\end_layout

\begin_layout Subsection
KKT conditions
\end_layout

\begin_layout Standard
The lagragian is given by
\begin_inset Formula 
\[
L(A,P,\mu)=-\langle X,\log(GPA)\rangle+\langle\mathbf{1}^{\ell,p},GPA\rangle+\mu\circ\left(-A\right)
\]

\end_inset

The KKT conditions for 
\begin_inset Formula $A$
\end_inset

 are
\begin_inset Formula 
\[
\nabla_{A}L(A,P,\mu)=\nabla_{A}\mathcal{L}(A,P)-\mu=0
\]

\end_inset


\begin_inset Formula 
\[
-A\leq\mathbf{0}^{k\times p}
\]

\end_inset


\begin_inset Formula 
\[
\mu\geq\mathbf{0}^{k\times p}
\]

\end_inset


\begin_inset Formula 
\[
A\circ\mu=\mathbf{0}^{k\times p}
\]

\end_inset

Using 
\begin_inset Formula $\nabla_{A}\mathcal{L}(A,P)=\mu,$
\end_inset

 we can rewrite these equations as 
\begin_inset Formula 
\[
\nabla_{A}\mathcal{L}(A,P)\geq\mathbf{0}^{k\times p}
\]

\end_inset


\begin_inset Formula 
\[
A\geq\mathbf{0}^{k\times p}
\]

\end_inset


\begin_inset Formula 
\[
\nabla_{A}\mathcal{L}(A,P)\circ A=\mathbf{0}^{k\times p}
\]

\end_inset

or simply
\begin_inset Formula 
\[
\min\left(\nabla_{A}\mathcal{L}(A,P),A\right)=\mathbf{0}^{k\times p}
\]

\end_inset


\end_layout

\begin_layout Subsection
Link with divergence
\end_layout

\begin_layout Standard
Let us consider the generalized KL divergence
\begin_inset Formula 
\[
D_{GKL}(B\|A)=\sum_{ij}B_{ij}\log\left(\frac{B_{ij}}{A_{ij}}\right)-B_{ij}+A_{ij}
\]

\end_inset

where we have by convention, we have 
\begin_inset Formula $\frac{0}{0}=0$
\end_inset

 and 
\begin_inset Formula $0\log0=0.$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
D\left(X\|GPA\right) & =\sum_{i,j}X_{ij}\log\left(\frac{X_{ij}}{\left[GPA\right]_{ij}}\right)-X_{ij}+\left[GPA\right]_{ij}\\
 & =\sum_{ij}X_{ij}\log\left(X_{ij}\right)-X_{ij}\log\left(\left[GPA\right]_{ij}\right)-X_{ij}+\left[GPA\right]_{ij}
\end{align*}

\end_inset

We observe that if we minimize 
\begin_inset Formula $D\left(X\|GPA\right)$
\end_inset

 with respect of 
\begin_inset Formula $P$
\end_inset

 and 
\begin_inset Formula $A,$
\end_inset

 we recover the loss: 
\begin_inset Formula $\sum_{ij}-X_{ij}\log\left(\left[GPA\right]_{ij}\right)+\left[GPA\right]_{ij}$
\end_inset

 by droping the terms that do not depend of 
\begin_inset Formula $P,A.$
\end_inset

 
\end_layout

\begin_layout Subsection
Toward an iterative algorithm
\end_layout

\begin_layout Standard
Let us consider a gradient step of 
\begin_inset Formula $A$
\end_inset

.
 We have 
\begin_inset Formula 
\begin{align*}
A_{t+1} & =A_{t}-\gamma\circ\nabla_{A}\mathcal{L}\vert_{A_{t},P_{t}}\\
 & =A_{t}-\gamma\circ\left(-P_{t}^{T}G_{t}^{T}\left(X\oslash G_{t}P_{t}A_{t}\right)+P_{t}^{T}G_{t}^{T}\mathbf{\mathbf{1}^{\ell,p}}\right)\\
 & =\left(A_{t}\oslash P_{t}^{T}G_{t}^{T}\mathbf{\mathbf{1}^{\ell,p}}\right)\circ\left(P_{t}^{T}G_{t}^{T}\left(X\oslash G_{t}P_{t}A_{t}\right)\right)
\end{align*}

\end_inset

where we used 
\begin_inset Formula $\gamma=A_{t}\oslash P_{t}^{T}G_{t}^{T}\mathbf{\mathbf{1}^{\ell,p}}$
\end_inset

.
 Similarly, the gradient step for 
\begin_inset Formula $P$
\end_inset

 is
\begin_inset Formula 
\begin{align*}
P_{t+1} & =P_{t}-\gamma\circ\nabla_{P}\mathcal{L}\vert_{A_{t},P_{t}}\\
 & =P_{t}-\gamma\circ\left(-G^{T}\left(X\oslash GPA\right)A^{T}+G^{T}\mathbf{1}^{\ell,p}A^{T}\right)\\
 & =\left(P_{t}\oslash G^{T}\mathbf{1}^{\ell,p}A^{T}\right)\circ\left(G^{T}\left(X\oslash GPA\right)A^{T}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Adding the constraints and regularizers
\end_layout

\begin_layout Standard
First we need to add the constraint that
\begin_inset Formula $A\mathbf{1}^{p}=\mathbf{1}^{k}$
\end_inset

.
 This force 
\begin_inset Formula $A$
\end_inset

 to have the correct normalization.
 Then we add the regularizer 
\begin_inset Formula $m^{T}\log(A)\mathbf{1}^{p}$
\end_inset

, where 
\begin_inset Formula $m$
\end_inset

 is a mask that select all the line of 
\begin_inset Formula $A$
\end_inset

 except the first, i.e.
 
\begin_inset Formula $m^{T}=[0,1,1,\dots,1]$
\end_inset

.
 The problem becomes
\begin_inset Formula 
\begin{align*}
\arg\min_{A\geq0,P\geq0,A\mathbf{1}^{P}=\mathbf{1}^{k}} & \mathcal{L}(A,P)\\
\text{where} & \mathcal{L}(A,P)=-\langle X,\log(GPA)\rangle+\langle\mathbf{1}^{\ell,p},GPA\rangle+\mu M\log(A+\epsilon)\mathbf{1}^{p}
\end{align*}

\end_inset

Let us write the lagrangian 
\begin_inset Formula 
\[
L(A,P,\lambda,\omega,\nu)=-\langle X,\log(GPA)\rangle+\langle\mathbf{1}^{\ell,p},GPA\rangle-\mu m^{T}\log(A+\epsilon)\mathbf{1}^{p}-\langle\lambda,A\rangle-\langle\omega,P\rangle+\nu^{T}\left(A\mathbf{1}^{p}-\mathbf{1}^{k}\right)
\]

\end_inset

Let us leave the positivity constraint for now and we have
\begin_inset Formula 
\[
\tilde{\mathcal{L}}(A,P,\nu)=-\langle X,\log(GPA)\rangle+\langle\mathbf{1}^{\ell,p},GPA\rangle+\mu m^{T}\log(A+\epsilon)\mathbf{1}^{p}+\nu^{T}\left(A\mathbf{1}^{p}-\mathbf{1}^{k}\right)
\]

\end_inset

Using 
\series bold

\begin_inset Formula $GP=D^{\prime},$
\end_inset


\series default
 we rewrite this 
\begin_inset Formula $\tilde{\mathcal{L}}(A,P,\nu)$
\end_inset

 as
\begin_inset Formula 
\[
\tilde{\mathcal{L}}(A,P,\nu)={\color{purple}-\sum_{\ell,p}X_{\ell,p}\log\left(\sum_{k}D_{\ell,k}^{\prime}A_{k,p}\right)}+\sum_{\ell,k,p}D_{\ell,k}^{\prime}A_{k,p}+\mu\sum_{k,p}m_{k}\log(A_{k,p}+\epsilon)+\sum_{k}\nu_{k}\left(\sum_{p}A_{kp}-1\right)
\]

\end_inset

Inspired by 
\backslash
cite{}, we define an auxiliary function
\begin_inset Formula 
\begin{align*}
G(A,A^{t}) & =\sum_{\ell,k,p}D_{\ell,k}^{\prime}A_{k,p}+\mu\sum_{k,p}m_{k}\log\left(A_{k,p}+\epsilon\right)+\sum_{k}\nu_{k}\left(\sum_{p}A_{kp}-1\right)\\
 & {\color{purple}-\sum_{\ell,i,p}X_{\ell,p}\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}\left(\log\left(D_{\ell,i}^{\prime}A_{i,p}\right)-\log\left(\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}\right)\right)}
\end{align*}

\end_inset

We make two observations.
 First 
\begin_inset Formula $\tilde{\mathcal{L}}(A,P,\nu)=G(A,A),$
\end_inset

 as 
\begin_inset Formula 
\begin{align*}
\text{purpleG}(A,A)= & -\sum_{\ell,i,p}X_{\ell,p}\frac{D_{\ell,i}^{\prime}A_{i,p}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}}\left(\log\left(D_{\ell,i}^{\prime}A_{i,p}\right)-\log\left(\frac{D_{\ell,i}^{\prime}A_{i,p}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}}\right)\right)\\
= & -\sum_{\ell,i,p}X_{\ell,p}\frac{D_{\ell,i}^{\prime}A_{i,p}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}}\log\left(\sum_{k}D_{\ell,k}^{\prime}A_{k,p}\right)\\
= & -\sum_{\ell,p}X_{\ell,p}\log\left(\sum_{k}D_{\ell,k}^{\prime}A_{k,p}\right)\sum_{i}\frac{D_{\ell,i}^{\prime}A_{i,p}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}}\\
= & -\sum_{\ell,p}X_{\ell,p}\log\left(\sum_{k}D_{\ell,k}^{\prime}A_{k,p}\right)=\text{purpleL(A)}.
\end{align*}

\end_inset

Second 
\begin_inset Formula $\tilde{\mathcal{L}}(A,P,\nu)\leq G(A,A^{t}),\forall A^{t}$
\end_inset

.
 By convexity of the 
\begin_inset Formula $-\log$
\end_inset

 function, 
\begin_inset Formula 
\begin{align*}
\text{purpleL(A)}= & -\sum_{\ell,p}X_{\ell,p}\log\left(\sum_{i}D_{\ell,i}^{\prime}A_{i,p}\right)\\
\leq & -\sum_{\ell,p}X_{\ell,p}\sum_{i}w_{\ell ip}^{t}\log\left(\frac{D_{\ell,i}^{\prime}A_{i,p}}{w_{\ell ip}^{t}}\right)
\end{align*}

\end_inset

for all non negative 
\begin_inset Formula $w_{\ell ip}^{t}$
\end_inset

 that sum to 
\begin_inset Formula $1$
\end_inset

, i.e.
 
\begin_inset Formula $\sum_{i}w_{\ell ip}^{t}=1$
\end_inset

.
 Let us select 
\begin_inset Formula $w_{\ell ip}^{t}=\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}},$
\end_inset

 we have 
\begin_inset Formula 
\[
\text{purpleL(A)}\leq\text{purpleG}(A,A^{t})
\]

\end_inset

This implies that 
\begin_inset Formula $G(A,A^{t})$
\end_inset

 is an auxiliary function of 
\begin_inset Formula $\tilde{\mathcal{L}}(A,P,\nu),$
\end_inset

 see 
\backslash
cite[Definition 1]{}.
 Hence by minimizing 
\begin_inset Formula $G(A,A^{t})$
\end_inset

 with respect of 
\begin_inset Formula $A$
\end_inset

, we obtain an non-increasing update for 
\begin_inset Formula $\tilde{\mathcal{L}}(A,P,\nu)$
\end_inset

, see 
\backslash
cite[Lemma 1]{}.
 
\end_layout

\begin_layout Subsection
Small remark about the auxiliary function
\end_layout

\begin_layout Standard
For simplicity, let us drop the constraint 
\begin_inset Formula $\sum_{k}\nu_{k}\left(\sum_{p}A_{kp}-1\right)$
\end_inset

 and the regularization 
\begin_inset Formula $\mu\sum_{k,p}m_{k}\log\left(A_{k,p}+\epsilon\right)$
\end_inset

 terms.
 We have
\begin_inset Formula 
\begin{align*}
G(A,A^{t}) & =\sum_{\ell,p}\left[-\sum_{i}X_{\ell,p}\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}\left(\log\left(D_{\ell,i}^{\prime}A_{i,p}\right)-\log\left(\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}\right)\right)+\sum_{i}D_{\ell,i}^{\prime}A_{i,p}\right]\\
 & =\sum_{\ell,p}\left[X_{\ell,p}\sum_{i}w_{i}^{t,\ell,k}\log\left(\frac{w_{i}^{t,\ell,k}}{Z_{i}^{\ell,p}}\right)+\sum_{i}Z_{i}^{\ell,p}\right]
\end{align*}

\end_inset

where we have set set 
\begin_inset Formula $w_{i}^{t,\ell,k}=\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}$
\end_inset

 and 
\begin_inset Formula $D_{\ell,i}^{\prime}A_{i,p}=Z_{i}^{\ell,p}$
\end_inset

.
 We have used
\begin_inset Formula 
\begin{align*}
-\sum_{i}Xw_{i}^{t}\left(\log\left(Z_{i}\right)-\log\left(w_{i}^{t}\right)\right) & =X\sum_{i}w_{i}^{t}\log\left(\frac{w_{i}^{t}}{Z_{i}}\right)
\end{align*}

\end_inset

Remember that the definition of the generalized KL divergence satisfies
\begin_inset Formula 
\[
D_{GKL}(B\|A)+\sum_{i}B_{i}-\sum_{i}A_{i}=\sum_{i}B_{i}\log\left(\frac{B_{i}}{A_{i}}\right)
\]

\end_inset

So we can rewrite 
\begin_inset Formula $G$
\end_inset

 as
\begin_inset Formula 
\begin{align*}
G(A,A^{t}) & =\sum_{\ell,p}\left[X_{\ell,p}\sum_{i}w_{i}^{t,\ell,k}\log\left(\frac{w_{i}^{t,\ell,k}}{Z_{i}^{\ell,p}}\right)+\sum_{i}Z_{i}^{\ell,p}\right]\\
 & =\sum_{\ell,p}\left[X_{\ell,p}\left(D_{GKL}(w^{t,\ell,k}\|Z^{\ell,p})+1-\sum_{i}Z_{i}^{\ell,p}\right)+\sum_{i}Z_{i}^{\ell,p}\right]\\
 & =\sum_{\ell,p}\left[X_{\ell,p}D_{GKL}(w^{t,\ell,k}\|Z^{\ell,p})+X_{\ell,p}+(1-X_{\ell,p})\sum_{i}Z_{i}^{\ell,p}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
G(A,A^{t})=F(A^{t})+\nabla F(A^{t})(A-A^{t})+\frac{1}{\gamma}D_{GKL}(A,A^{t})
\]

\end_inset

I am not sure where I am going.
 We have established that
\begin_inset Formula 
\[
G(A,A^{t})\ge\mathcal{L}(A,D)
\]

\end_inset


\begin_inset Formula 
\begin{align*}
\mathcal{L}(A,D) & =\sum_{\ell,p}\left[-X_{\ell,p}\log\left(\sum_{i}D_{\ell,i}^{\prime}A_{i,p}\right)+\sum_{i}D_{\ell,i}^{\prime}A_{i,p}\right]\\
 & =\sum_{\ell,p}\left[-X_{\ell,p}\log\left(\sum_{i}Z_{i}^{\ell,p}\right)+\sum_{i}Z_{i}^{\ell,p}\right]
\end{align*}

\end_inset

Note that the generalized KL divergence is a particular case of the bregman
 divergence
\begin_inset Formula 
\[
D_{f}(B\|A)=f(B)-\langle\nabla f(A),B-A\rangle-f(A),
\]

\end_inset

 where 
\begin_inset Formula $f(A)=\sum_{i}A_{i}\log(A_{i})=-H(A)$
\end_inset

.
\end_layout

\begin_layout Standard
Let us assume that we have 
\begin_inset Formula $f(A)=\sum_{i}A_{i}\log(A_{i})$
\end_inset

, then 
\begin_inset Formula $\nabla f(A)=\log\left(A\right)+1$
\end_inset


\begin_inset Formula 
\begin{align*}
D_{f}(B\|A) & =f(B)-\langle\nabla f(A),B-A\rangle-f(A)\\
 & =\sum_{i}B_{i}\log(B_{i})-\langle\log\left(A\right)+1,B-A\rangle-\sum_{i}A_{i}\log(A_{i})\\
 & =\sum_{i}\left[B_{i}\log(B_{i})-B_{i}\log\left(A_{i}\right)-B_{i}+A_{i}\right]\\
 & =D_{GKL}(B\|A)
\end{align*}

\end_inset


\begin_inset Formula 
\[
-X_{\ell,p}\log\left(\sum_{i}Z_{i}^{\ell,p}\right)\leq-X_{\ell,p}\sum_{i}w_{\ell ip}^{t}\log\left(\frac{Z_{i}^{\ell,p}}{w_{\ell ip}^{t}}\right)
\]

\end_inset


\end_layout

\begin_layout Subsection
Finding the minimum of the auxiliary function
\end_layout

\begin_layout Standard
Let us search for the 
\begin_inset Formula $A$
\end_inset

 such that the gradient of 
\begin_inset Formula $G(A,A^{t})$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset


\begin_inset Formula 
\begin{align*}
\frac{\partial G(A,A^{t})}{\partial A_{k_{0},p_{0}}} & =\sum_{\ell}D_{\ell,k_{0}}^{\prime}+\mu_{k_{0}}\frac{1}{A_{k_{0},p_{0}}+\epsilon}+\nu_{k_{0}}\\
 & -\frac{1}{A_{k_{0},p_{0}}}\sum_{\ell}X_{\ell,p_{0}}\frac{D_{\ell,k_{0}}^{\prime}A_{k_{0},p_{0}}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p_{0}}^{t}}\\
 & =0
\end{align*}

\end_inset

Let us linearize the log around 
\begin_inset Formula $A_{k_{0},p_{0}}+\epsilon.$
\end_inset

 We have 
\begin_inset Formula 
\[
\log(\epsilon+x)_{x\rightarrow a}\approx\log(\epsilon+a)+\frac{x-a}{\epsilon+a}
\]

\end_inset

which as a derivative of 
\begin_inset Formula $\frac{1}{\epsilon+a}$
\end_inset

 in 
\begin_inset Formula $a$
\end_inset

.
 If we assume that 
\begin_inset Formula $A_{k_{0},p_{0}}^{t}\approx A_{k_{0},p_{0}}$
\end_inset

, which implies we update 
\begin_inset Formula $A$
\end_inset

, slowly, we have for the derivative
\begin_inset Formula 
\begin{align*}
\frac{\partial G(A,A^{t})}{\partial A_{k_{0},p_{0}}} & =\sum_{\ell}D_{\ell,k_{0}}^{\prime}+\mu_{k_{0}}\frac{1}{A_{k_{0},p_{0}}^{t}+\epsilon}+\nu_{k_{0}}\\
 & -\frac{1}{A_{k_{0},p_{0}}}\sum_{\ell}X_{\ell,p_{0}}\frac{D_{\ell,k_{0}}^{\prime}A_{k_{0},p_{0}}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p_{0}}^{t}}=0
\end{align*}

\end_inset

which leads to 
\begin_inset Formula 
\[
A_{k_{0},p_{0}}=A_{k_{0},p_{0}}^{t}\frac{\sum_{\ell}\frac{X_{\ell,p_{0}}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p_{0}}^{t}}D_{\ell,k_{0}}^{\prime}}{\sum_{\ell}D_{\ell,k_{0}}^{\prime}+\nu_{k_{0}}+\frac{\mu_{k_{0}}}{A_{k_{0},p_{0}}^{t}+\epsilon}}
\]

\end_inset

Eventually, we need to find the 
\begin_inset Formula $\nu_{k_{0}}$
\end_inset

 such that 
\begin_inset Formula $\sum_{p_{0}}A_{k_{0},p_{0}}=1.$
\end_inset

 Basically, we need to solve: 
\begin_inset Formula 
\begin{align*}
\sum_{i}A_{i} & =\sum_{i}\frac{a_{i}}{b_{i}+\nu}=1
\end{align*}

\end_inset

Assuming 
\begin_inset Formula $a_{i}>0$
\end_inset

, 
\begin_inset Formula $b_{i}\geq0$
\end_inset

 and 
\begin_inset Formula $\nu\geq0.$
\end_inset

 This can be done using dichotomy as implemented by Adrien.
 
\end_layout

\begin_layout Section
Adding a smooth term
\end_layout

\begin_layout Standard
Let us consider the following objective function
\begin_inset Formula 
\begin{align*}
\mathcal{L}_{S}(A,P) & ={\color{magenta}-\langle X,\log(GPA)\rangle+\langle\mathbf{1}^{\ell,p},GPA\rangle}{\color{green}+\mu M\log(A+\epsilon)\mathbf{1}^{p}}{\color{blue}+\frac{\lambda}{2}\text{tr}\left(A^{T}\Delta A\right)}\\
 & ={\color{magenta}\mathcal{L}(A,P)}{\color{green}+R_{1}(A)}{\color{blue}+R_{2}(A)}
\end{align*}

\end_inset

We create an auxiliary function 
\begin_inset Formula $G$
\end_inset

 such that all these three function are upper bounded.
 
\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula ${\color{magenta}\mathcal{L}(A,P)}$
\end_inset

, we set 
\begin_inset Formula $w_{i}^{t,\ell,k}=\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}$
\end_inset

 and 
\begin_inset Formula $D_{\ell,i}^{\prime}A_{i,p}=Z_{i}^{\ell,p}$
\end_inset

 and obtain
\begin_inset Formula 
\begin{align*}
{\color{magenta}\mathcal{L}(A,P)} & \leq\sum_{\ell,p}\left[X_{\ell,p}\sum_{i}w_{i}^{t,\ell,k}\log\left(\frac{w_{i}^{t,\ell,k}}{Z_{i}^{\ell,p}}\right)+\sum_{i}Z_{i}^{\ell,p}\right]\\
 & =\sum_{\ell,p}\left[-\sum_{i}X_{\ell,p}\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}\left(\log\left(D_{\ell,i}^{\prime}A_{i,p}\right)-\log\left(\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}\right)\right)+\sum_{i}D_{\ell,i}^{\prime}A_{i,p}\right]
\end{align*}

\end_inset

This comes from the fact that
\begin_inset Formula 
\[
-\sum_{\ell,p}X_{\ell,p}\log\left(\sum_{i}Z_{i}^{\ell,p}\right)\leq-\sum_{\ell,p}X_{\ell,p}\sum_{i}w_{\ell ip}^{t}\log\left(\frac{Z_{i}^{\ell,p}}{w_{\ell ip}^{t}}\right)
\]

\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula ${\color{green}R_{1}(A)},$
\end_inset

 we linearize the function around 
\begin_inset Formula $A^{t}$
\end_inset

 and thanks to concavity, we have
\begin_inset Formula 
\[
{\color{green}R_{1}(A)\leq\sum_{k,p}\mu_{k}\left[\log\left(A_{k,p}^{t}+\epsilon\right)+\frac{A-A_{k,p}^{t}}{\epsilon+A_{k,p}^{t}}\right]}
\]

\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula ${\color{blue}R_{2}(A)},$
\end_inset

 we use the key computation presented bellow
\begin_inset Formula 
\begin{align*}
{\color{blue}R_{2}(A)} & =\frac{\lambda}{2}\text{tr}\left(A^{T}\Delta A\right)\\
 & =\frac{\lambda}{2}\sum_{k}A_{k}^{T}\Delta A_{k}\\
 & \leq\frac{\lambda}{2}\sum_{k}A_{k}^{t}{}^{T}\Delta A_{k}^{t}+2\left(A_{k}-A_{k}^{t}\right)^{T}\Delta A_{k}^{t}+2\sigma(\Delta)\left(\max_{k,p}A_{k,p}^{t}\right)\sum_{p,k}\left(A_{k,p}^{t}\log\left(\frac{A_{k,p}^{t}}{A_{k,p}}\right)-A_{k,p}^{t}+A_{k,p}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
As a result, we create an auxiliary defined as 
\begin_inset Formula 
\begin{align*}
G\left(A,A^{t}\right) & =\sum_{\ell,p}\left[-\sum_{i}X_{\ell,p}\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}\left(\log\left(D_{\ell,i}^{\prime}A_{i,p}\right)-\log\left(\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}\right)\right)+\sum_{i}D_{\ell,i}^{\prime}A_{i,p}\right]\\
 & +\sum_{k,p}\mu_{k}\left[\log\left(A_{k,p}^{t}+\epsilon\right)+\frac{A-A_{k,p}^{t}}{\epsilon+A_{k,p}^{t}}\right]+\sum_{k}\nu_{k}\left(\sum_{p}A_{kp}-1\right)\\
 & +\frac{\lambda}{2}\sum_{i}\left[A_{i}^{t}{}^{T}\Delta A_{i}^{t}+2\left(A_{i}-A_{i}^{t}\right)^{T}\Delta A_{i}^{t}\right]+2\sigma(\Delta)\left(\max_{i,p}A_{i,p}^{t}\right)\sum_{i,p}\left(A_{i,p}^{t}\log\left(\frac{A_{i,p}^{t}}{A_{i,p}}\right)-A_{i,p}^{t}+A_{i,p}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Computation of the auxiliary function minimum
\end_layout

\begin_layout Standard
Let us compute the gradient of the auxiliary function 
\begin_inset Formula $G$
\end_inset

 with respect of 
\begin_inset Formula $A$
\end_inset

 
\begin_inset Formula 
\begin{align*}
\frac{\partial G(A,A^{t})}{\partial A_{k_{0},p_{0}}} & =\sum_{\ell}D_{\ell,k_{0}}^{\prime}-\frac{1}{A_{k_{0},p_{0}}}\sum_{\ell}X_{\ell,p_{0}}\frac{D_{\ell,k_{0}}^{\prime}A_{k_{0},p_{0}}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p_{0}}^{t}}\\
 & +\frac{\mu_{k_{0}}}{\epsilon+A_{k_{0},p_{0}}^{t}}+\nu_{k_{0}}\\
 & +\frac{\lambda}{2}\left[2\sum_{k_{2}}A_{p_{0},k_{2}}^{tT}\Delta_{k_{2}k_{0}}+2\sigma(\Delta)\left(\max_{k,p}A_{k,p}^{t}\right)\left(-\frac{A_{k_{0},p_{0}}^{t}}{A_{k_{0},p_{0}}}+1\right)\right]\\
 & =-\frac{1}{A_{k_{0},p_{0}}}\left(\sum_{\ell}X_{\ell,p_{0}}\frac{D_{\ell,k_{0}}^{\prime}A_{k_{0},p_{0}}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p_{0}}^{t}}+\lambda\sigma(\Delta)\left(\max_{k,p}A_{k,p}^{t}\right)A_{k_{0},p_{0}}^{t}\right)\\
 & +\sum_{\ell}D_{\ell,k_{0}}^{\prime}+\frac{\mu_{k_{0}}}{\epsilon+A_{k_{0},p_{0}}^{t}}+\lambda\sum_{k_{2}}A_{p_{0},k_{2}}^{tT}\Delta_{k_{2}k_{0}}+\lambda\sigma(\Delta)\left(\max_{k,p}A_{k,p}^{t}\right)+\nu_{k_{0}}\\
 & =0
\end{align*}

\end_inset

So we obtain we obtain the following solution
\begin_inset Formula 
\[
A_{k_{0},p_{0}}=A_{k_{0},p_{0}}^{t}\frac{\sum_{\ell}X_{\ell,p_{0}}\frac{D_{\ell,k_{0}}^{\prime}A_{k_{0},p_{0}}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p_{0}}^{t}}+\lambda\sigma(\Delta)\left(\max_{k,p}A_{k,p}^{t}\right)A_{k_{0},p_{0}}^{t}}{\sum_{\ell}D_{\ell,k_{0}}^{\prime}+\frac{\mu_{k_{0}}}{\epsilon+A_{k_{0},p_{0}}^{t}}+\lambda\sum_{k_{2}}A_{p_{0},k_{2}}^{tT}\Delta_{k_{2}k_{0}}+\lambda\sigma(\Delta)\left(\max_{k,p}A_{k,p}^{t}\right)+\nu_{k_{0}}}
\]

\end_inset


\end_layout

\begin_layout Section
Key computation
\end_layout

\begin_layout Standard
In this subsection, we prove that
\begin_inset Formula 
\begin{align*}
p^{T}Lp & \le p_{t}^{T}Lp_{t}+2\left(p-p_{t}\right)^{T}Lp_{t}+2\sigma(L)\left(\max_{i}p_{i}\right)D_{GKL}\left(p_{t}||p\right),\\
 & =p_{t}^{T}Lp_{t}+2\left(p-p_{t}\right)^{T}Lp_{t}+2\sigma(L)\left(\max_{i}p_{i}\right)\left(\sum_{i=1}^{k}p_{i}\log\left(\frac{p_{ti}}{p_{i}}\right)-\sum_{i=1}^{k}p_{ti}+\sum_{i=1}^{k}p_{i}\right)
\end{align*}

\end_inset


\begin_inset Formula $\forall p,p_{t}\in\mathbb{R}^{k}$
\end_inset

, 
\begin_inset Formula $L\in\mathbb{R}^{k\times k}$
\end_inset

 and 
\begin_inset Formula $\sigma(L)=\|L\|_{op}.$
\end_inset

 
\end_layout

\begin_layout Standard
Here is some key computation
\begin_inset Formula 
\[
\|p-q\|^{2}\leq2D_{GKL}\left(p||q\right)
\]

\end_inset

given 
\begin_inset Formula $p,q\in\mathbb{R}^{k}$
\end_inset


\begin_inset Formula 
\[
H(p)=-\sum_{i=1}^{k}p_{i}\log\left(p_{i}\right)
\]

\end_inset

and 
\begin_inset Formula $V(p)=-H(p)$
\end_inset

, 
\begin_inset Formula $\nabla V(p)=\log\left(p\right)+1$
\end_inset

.
 So we have
\begin_inset Formula 
\begin{align*}
D_{GKL}\left(p||q\right) & =\sum_{i=1}^{k}p_{i}\log\left(\frac{p_{i}}{q_{i}}\right)-\sum_{i=1}^{k}p_{i}+\sum_{i=1}^{k}q_{i}\\
 & =\sum_{i=1}^{k}p_{i}\log\left(p_{i}\right)-\sum_{i=1}^{k}p_{i}\log\left(q_{i}\right)-\sum_{i=1}^{k}p_{i}+\sum_{i=1}^{k}q_{i}\\
 & =\sum_{i=1}^{k}p_{i}\log\left(p_{i}\right)-\sum_{i=1}^{k}q_{i}\log\left(q_{i}\right)-\sum_{i}\left[\left(\log\left(q_{i}\right)+1\right)\left(p_{i}-q_{i}\right)\right]\\
 & =D_{V}(p\|q)\\
 & =V(p)-\left(V(q)+\nabla V(q)^{T}(p-q)\right)\\
 & =\frac{1}{2}\left(q-p\right)^{T}\mathcal{H}(\tilde{p})\left(q-p\right)\\
 & \geq\frac{1}{2}\frac{1}{\max_{i}p_{i}}\|p-q\|^{2}
\end{align*}

\end_inset

There exist at least a 
\begin_inset Formula $\tilde{p}$
\end_inset

 such that this is true.
 Similarly, we can show that 
\begin_inset Formula $D_{GKL}\left(q||p\right)\geq\frac{1}{2}\|p-q\|^{2}$
\end_inset

 The last inequality comes from the fact that for 
\begin_inset Formula $V(p)=-H(p),$
\end_inset


\begin_inset Formula 
\[
\mathcal{H}(p)=\left[\frac{\partial^{2}V}{\partial p_{i}\partial p_{j}}\right]_{ij}\geq\frac{1}{\max_{i}p_{i}}I
\]

\end_inset

since
\begin_inset Formula 
\[
\frac{\partial V}{\partial p_{i}}\log\left(p_{i}\right)+1\hspace{1em}\text{and}\hspace{1em}\frac{\partial^{2}V}{\partial p_{i}\partial p_{j}}=\delta_{ij}\frac{1}{p_{i}}\geq\frac{1}{\max_{i}p_{i}}.
\]

\end_inset

Furthermore a tailor developement of 
\begin_inset Formula $p^{T}Lp$
\end_inset

 gives 
\begin_inset Formula 
\begin{align*}
p^{T}Lp & =p_{t}^{T}Lp_{t}+2\left(p-p_{t}\right)^{T}Lp_{t}+\left(p-p_{t}\right)^{T}L\left(p-p_{t}\right)\\
 & \leq p_{t}^{T}Lp_{t}+2\left(p-p_{t}\right)^{T}Lp_{t}+\sigma(L)\|p-p_{t}\|^{2}\\
 & \leq p_{t}^{T}Lp_{t}+2\left(p-p_{t}\right)^{T}Lp_{t}+2\left(\max_{i}p_{i}\right)\sigma(L)D_{GKL}\left(p_{t}||p\right)
\end{align*}

\end_inset

Note that is only true if 
\begin_inset Formula $p\leq1!!!!$
\end_inset

 If 
\begin_inset Formula $p_{t}>1,$
\end_inset

 we can simply renormalize the bound
\end_layout

\begin_layout Section
Two-metrics
\end_layout

\begin_layout Standard
\begin_inset Formula $A$
\end_inset

 should be on the simplex.
 But problematically, the updates get us out of the simplex.
 If you minimize
\begin_inset Formula 
\[
L(p)=D_{KL}\left(p||q\right)+a^{T}q
\]

\end_inset


\begin_inset Formula 
\[
f(a)\leq f(a_{t})+\nabla f(a_{t})^{T}\left(a-a_{t}\right)+\gamma D_{GKL}(a_{t}||a)=\tilde{f}_{t}(a)
\]

\end_inset

such that 
\begin_inset Formula $a$
\end_inset

 is in the simplex.
 Because everything is convex, we can replace
\begin_inset Formula $\nabla f(a_{t})^{T}$
\end_inset

 by its projection.
\end_layout

\begin_layout Section
Alteranative to dichotomy
\end_layout

\begin_layout Standard
Problematically, the dicotomy might not lead the correct root.
 Let us write the function
\begin_inset Formula 
\[
f(\nu)=\sum_{i}\frac{a_{i}}{b_{i}+\nu}-1
\]

\end_inset

If 
\begin_inset Formula $f(0)\geq0,$
\end_inset

 then we would like to find the smallest 
\begin_inset Formula $\nu$
\end_inset

such that Another approach would be to start with 
\begin_inset Formula $\nu$
\end_inset

 eqal 0
\end_layout

\begin_layout Subsection
Alternative solution
\end_layout

\begin_layout Standard
Since the problem is convex both in 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $P$
\end_inset

 (but not jointly), we can solve alternatively
\begin_inset Formula 
\[
A_{t+1}=\arg\min_{A\geq0,A,\mathbf{1}^{P}=\mathbf{1}^{k}}-\langle X,\log(GP_{t}A)\rangle+\langle\mathbf{1}^{\ell,p},GP_{t}A\rangle
\]

\end_inset


\begin_inset Formula 
\[
P_{t+1}=\arg\min_{P\geq0}-\langle X,\log(GPA_{t+1})\rangle+\langle\mathbf{1}^{\ell,p},GPA_{t+1}\rangle
\]

\end_inset


\end_layout

\begin_layout Standard
Let us first compute the proximal operator of the function 
\begin_inset Formula $f(Z)=-\langle X,\log\left(Z\right)\rangle.$
\end_inset

 We have 
\begin_inset Formula 
\[
\text{prox}_{f}\left(Y,\lambda\right)=\arg\min_{Z}\frac{1}{2}\|Z-Y\|_{2}^{2}-\lambda\langle X,\log\left(Z\right)\rangle
\]

\end_inset

To find the solution, we find the point with a zero gradient: 
\begin_inset Formula $Z-Y-\lambda X\oslash Z=\mathbf{0.}$
\end_inset

 Assuming that 
\begin_inset Formula $Z>0,$
\end_inset

 We find the second order equation 
\begin_inset Formula 
\[
Z\circ Z-YZ-\lambda X=\mathbf{0},
\]

\end_inset

 which gives us 
\begin_inset Formula $\frac{1}{2}\left(Y\pm\sqrt{Y\circ Y+4\lambda X}\right).$
\end_inset

 As the solution has to be positive, we have 
\begin_inset Formula 
\[
\text{prox}_{f}\left(Y,\lambda\right)=\frac{1}{2}\left(Y+\sqrt{Y\circ Y+4\lambda X}\right).
\]

\end_inset

Adding the constraints and regularizers
\end_layout

\begin_layout Section
L2 algorithm
\end_layout

\begin_layout Standard
Let us consider the following optimization problem
\begin_inset Formula 
\begin{align*}
\arg\min_{A\geq0,P\geq0} & \mathcal{L}(A,P)\\
\text{where} & \mathcal{L}(A,P)=\frac{1}{2}\|GPA-X\|_{F}^{2}{\color{green}+\mu^{T}\log(A+\epsilon)\mathbf{1}^{p}}{\color{blue}+\frac{\lambda}{2}\text{tr}\left(A^{T}\Delta A\right)+\left(\mathbf{1}^{cT}A-\mathbf{1}^{p}\right)\nu}
\end{align*}

\end_inset

The gradient is given by
\begin_inset Formula 
\begin{align*}
\nabla_{P}\mathcal{L}(A,P) & =G^{T}(GPA-X)A^{T}\\
 & =G^{T}GPAA^{T}-G^{T}XA^{T}
\end{align*}

\end_inset


\begin_inset Formula 
\begin{align*}
\nabla_{A}\mathcal{L}(A,P) & =P^{T}G^{T}(GPA-X)+\mu^{T}\mathbf{1}^{p}\oslash(A+\epsilon)+\lambda\Delta A+\mathbf{1}^{c}\nu^{T}\\
 & =P^{T}G^{T}GPA-P^{T}G^{T}X+\mu^{T}\mathbf{1}^{p}\oslash(A+\epsilon)+\lambda\Delta A
\end{align*}

\end_inset

A gradient step can be done as
\begin_inset Formula 
\begin{align*}
P_{t+1} & =P_{t}-\gamma\nabla_{P}\mathcal{L}(A_{t},P_{t})\\
 & =P_{t}-\gamma G^{T}GP_{t}A_{t}A_{t}^{T}+\gamma G^{T}XA_{t}^{T}\\
 & =P_{t}\oslash G^{T}GP_{t}A_{t}A_{t}^{T}\circ G^{T}XA_{t}^{T}
\end{align*}

\end_inset


\begin_inset Formula 
\begin{align*}
A_{t+1} & =A_{t}-\gamma\nabla_{P}\mathcal{L}(A_{t},P_{t})\\
 & =A_{t}-\gamma\left(P^{T}G^{T}GPA-P^{T}G^{T}X+\mu^{T}\mathbf{1}^{p}\oslash(A+\epsilon)+\lambda\Delta A+\mathbf{1}^{c}\nu^{T}\right)\\
 & =A_{t}\oslash\left(P^{T}G^{T}GPA+\lambda\Delta A+\mu^{T}\mathbf{1}^{p}\oslash(A+\epsilon)+\mathbf{1}^{c}\nu^{T}\right)\circ P^{T}G^{T}X
\end{align*}

\end_inset

where 
\begin_inset Formula $\gamma=P_{t}\oslash G^{T}GP_{t}A_{t}A_{t}^{T}$
\end_inset

 and 
\begin_inset Formula $A_{t}\oslash\left(P^{T}G^{T}GPA+\lambda\Delta A+\mu^{T}\mathbf{1}^{p}\oslash(A+\epsilon)+\mathbf{1}^{c}\nu^{T}\right)$
\end_inset

.
\end_layout

\begin_layout Section
Projected algorithm
\end_layout

\begin_layout Standard
The definition of the Bregman divergence is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
D_{f}(B\|A)=f(B)-\langle\nabla f(A),B-A\rangle-f(A)
\]

\end_inset

 If we select 
\begin_inset Formula $f(A)=\sum_{i}A_{i}\log(A_{i})=-H(A)$
\end_inset

, we have 
\begin_inset Formula $\nabla f(A)=\log\left(A\right)+1$
\end_inset

 and
\begin_inset Formula 
\begin{align*}
D_{f}(B\|A) & =f(B)-\langle\nabla f(A),B-A\rangle-f(A)\\
 & =\sum_{i}B_{i}\log(B_{i})-\langle\log\left(A\right)+1,B-A\rangle-\sum_{i}A_{i}\log(A_{i})\\
 & =\sum_{i}\left[B_{i}\log(B_{i})-B_{i}\log\left(A_{i}\right)-B_{i}+A_{i}\right]\\
 & =D_{GKL}(B\|A)
\end{align*}

\end_inset

From the definition, we have
\begin_inset Formula 
\[
f(B)=f(A)+\langle\nabla f(A),B-A\rangle+D_{f}(B\|A)
\]

\end_inset

Let us use this relation in our problem and assume we would like to minimize
 
\begin_inset Formula $-\langle X,\log(GPA)\rangle+\langle\mathbf{1}^{\ell,p},GPA\rangle$
\end_inset

.
 We start with 
\begin_inset Formula $f(A)=-\langle X,\log(GPA)\rangle$
\end_inset

 and find 
\begin_inset Formula 
\begin{align*}
f(A) & =f(A_{t})+\langle\nabla f(A^{t}),A-A^{t}\rangle+D_{f}(A\|A^{t})\\
 & =-\langle X,\log(GPA^{t})\rangle+\langle\nabla f(A^{t}),A-A^{t}\rangle+D_{f}(A\|A^{t})\\
 & =
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Idea from Guillaume
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f(x) & \leq f(x_{t})+\langle\nabla f(x_{t}),x-x_{t}\rangle+D_{B}(x\|x_{t})\\
 & =f(x_{t})+\langle\Pi\nabla f(x_{t}),x-x_{t}\rangle+D_{B}(x_{t}\|x)
\end{align*}

\end_inset


\begin_inset Formula 
\[
\text{s.t. }x\in S
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $D_{B}$
\end_inset

 is the bregman divergence
\begin_inset Formula 
\[
D_{B}(x_{t}\|x)=-\sum_{i}x_{ti}\log\left(\frac{x_{i}}{x_{it}}\right)
\]

\end_inset


\begin_inset Formula $\Pi:$
\end_inset

 projection on 
\begin_inset Formula $\{x|x^{T}1=0\}$
\end_inset


\begin_inset Formula 
\[
\min_{x_{i}}\sum_{i=1}^{K}g_{ti}x_{i}-\sum
\]

\end_inset


\end_layout

\begin_layout Standard
regle d'Armiro
\end_layout

\begin_layout Subsection
Some tests
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula 
\[
F(A)=-\langle X,\log(DA)\rangle+\langle\mathbf{1}^{\ell,p},DA\rangle
\]

\end_inset

and define 
\begin_inset Formula $G(A,A^{t})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
G(A,A^{t})=F(A^{t})+\nabla F(A^{t})(A-A^{t})+\frac{1}{\gamma}D_{F}(A\|A^{t})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nabla F(A^{t})=-D^{T}\left(X\oslash DA\right)+D^{T}\mathbf{\mathbf{1}}^{\ell,p}
\]

\end_inset


\begin_inset Formula 
\begin{align*}
D_{F}(A\|A^{t}) & =F(A)-\langle\nabla F(A^{t}),A-A^{t}\rangle-F(A^{t})\\
 & =-\langle X,\log(DA)\rangle+\langle\mathbf{1}^{\ell,p},DA\rangle\\
 & +\langle D^{T}\left(X\oslash DA^{t}\right),(A-A^{t})\rangle-\langle D^{T}\mathbf{\mathbf{1}}^{\ell,p},(A-A^{t})\rangle\\
 & +\langle X,\log(DA^{t})\rangle-\langle\mathbf{1}^{\ell,p},DA^{t}\rangle
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
G(A,A^{t}) & =\sum_{\ell,p}\left[-\sum_{i}X_{\ell,p}\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}\left(\log\left(D_{\ell,i}^{\prime}A_{i,p}\right)-\log\left(\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}\right)\right)+\sum_{i}D_{\ell,i}^{\prime}A_{i,p}\right]\\
 & =\sum_{\ell,p}\left[X_{\ell,p}\sum_{i}w_{i}^{t,\ell,k}\log\left(\frac{w_{i}^{t,\ell,k}}{Z_{i}^{\ell,p}}\right)+\sum_{i}Z_{i}^{\ell,p}\right]
\end{align*}

\end_inset

where we have set set 
\begin_inset Formula $w_{i}^{t,\ell,k}=\frac{D_{\ell,i}^{\prime}A_{i,p}^{t}}{\sum_{k}D_{\ell,k}^{\prime}A_{k,p}^{t}}$
\end_inset

 and 
\begin_inset Formula $D_{\ell,i}^{\prime}A_{i,p}=Z_{i}^{\ell,p}$
\end_inset

.
 We have used
\begin_inset Formula 
\begin{align*}
-\sum_{i}Xw_{i}^{t}\left(\log\left(Z_{i}\right)-\log\left(w_{i}^{t}\right)\right) & =X\sum_{i}w_{i}^{t}\log\left(\frac{w_{i}^{t}}{Z_{i}}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Guillaume rederivation with Itakura Saito
\end_layout

\begin_layout Standard
The general loss is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathcal{L}(A,D)=\sum_{\ell,p}\left[-X_{\ell,p}\log\left(\sum_{k}D_{\ell,k}^{\prime}A_{k,p}\right)+\sum_{k}D_{\ell,k}^{\prime}A_{k,p}\right]
\]

\end_inset

Let us focus on the function
\begin_inset Formula 
\begin{align*}
f(x,a,d) & :=-x\log\left(\sum_{i}a_{i}d_{i}\right)+\sum_{i}a_{i}d_{i}\\
 & =-x\log\left(\sum_{i}\frac{a_{i}d_{i}}{q_{i}}q_{i}\right)+\sum_{i}a_{i}d_{i}\\
 & \leq-x\sum_{i}q_{i}\log\left(\frac{a_{i}d_{i}}{q_{i}}\right)+\sum_{i}a_{i}d_{i}
\end{align*}

\end_inset

for 
\begin_inset Formula $\sum_{i}q_{i}=1$
\end_inset

, 
\begin_inset Formula $q_{i}>0$
\end_inset

.
 The last line follow from the Jensen inequality.
 Note that we have an equality for 
\begin_inset Formula 
\[
q_{i}=q_{i}^{*}=\frac{a_{i}d_{i}}{\sum_{j}a_{j}d_{j}}.
\]

\end_inset

This can be verified using
\begin_inset Formula 
\begin{align*}
\sum_{i}q_{i}^{*}\log\left(\frac{a_{i}d_{i}}{q_{i}^{*}}\right) & =\sum_{i}\frac{a_{i}d_{i}}{\sum_{j}a_{j}d_{j}}\log\left(\frac{a_{i}d_{i}}{\frac{a_{i}d_{i}}{\sum_{j}a_{j}d_{j}}}\right)\\
 & =\log\left(\sum_{j}a_{j}d_{j}\right)\frac{\sum_{i}a_{i}d_{i}}{\sum_{j}a_{j}d_{j}}\\
 & =\log\left(\sum_{j}a_{j}d_{j}\right).
\end{align*}

\end_inset

 Let us define
\begin_inset Formula 
\[
f_{J}(x,a,d,q):=-x\sum_{i}q_{i}\log\left(\frac{a_{i}d_{i}}{q_{i}}\right)+\sum_{i}a_{i}d_{i}
\]

\end_inset

Now les us write an auxiliary objective function
\begin_inset Formula 
\begin{align*}
\mathcal{L}_{J}(A,D,Q) & :=\sum_{\ell,p}\left[f_{J}(X_{\ell,p},A_{\cdot,p},D_{\ell,\cdot},Q_{\ell,p})\right]\\
 & =\sum_{\ell,p}\left[-X_{\ell,p}\sum_{k}Q_{\ell,p,k}\log\left(\frac{A_{k,p}D_{\ell,k}}{Q_{\ell,p,k}}\right)+\sum_{k}A_{k,p}D_{\ell,k}\right]\\
 & =-\sum_{p,k}\log\left(A_{k,p}\right)\sum_{\ell}X_{\ell,p}Q_{\ell,p,k}\\
 & -\sum_{\ell,k}\log\left(D_{\ell,k}\right)\sum_{p}X_{\ell,p}Q_{\ell,p,k}\\
 & +\sum_{\ell,p}\sum_{k}X_{\ell,p}Q_{\ell,p,k}\log\left(Q_{\ell,p,k}\right)\\
 & +\sum_{\ell,p}\sum_{k}A_{k,p}D_{\ell,k}
\end{align*}

\end_inset


\begin_inset Formula 
\[
\mathcal{L}(A,D)\leq\mathcal{L}_{J}(A,D,Q)
\]

\end_inset

Note that minimizing 
\begin_inset Formula $\mathcal{L}_{J}(A,D,Q)$
\end_inset

 with respect of 
\begin_inset Formula $A,D$
\end_inset

 is simple.
 (If we do not add further constraint, one can find a closed form solution.)
 The smooth regularizer is given by 
\begin_inset Formula 
\[
\frac{\lambda}{2}\text{tr}\left(A^{T}\Delta A\right)
\]

\end_inset


\begin_inset Formula 
\begin{align*}
\tilde{\psi_{t}}\left(A^{t},A\right) & =\frac{\lambda}{2}\text{tr}\left(A^{T}\Delta A\right)=\frac{\lambda}{2}\sum_{k}A_{k}^{T}\Delta A_{k}\\
 & =\frac{\lambda}{2}\sum_{k}A_{k}^{tT}\Delta A_{k}^{t}+\lambda\sum_{k}\left(A_{k}-A_{k}^{t}\right)^{T}\Delta A_{k}^{t}+\frac{\lambda}{2}\sum_{k}\left(A_{k}-A_{k}^{t}\right)^{T}\Delta\left(A_{k}-A_{k}^{t}\right)\\
 & \leq\frac{\lambda}{2}\sum_{k}A_{k}^{tT}\Delta A_{k}^{t}+\lambda\sum_{k}\left(A_{k}-A_{k}^{t}\right)^{T}\Delta A_{k}^{t}+\sigma(\Delta)\frac{\lambda}{2}\sum_{k}\|A_{k}-A_{k}^{t}\|^{2}
\end{align*}

\end_inset

I believe that minimizing with respect of 
\begin_inset Formula $Q$
\end_inset

 is simply doing 
\begin_inset Formula 
\[
\dot{Q_{\ell,p,i}}=\frac{A_{i,p}D_{\ell,i}}{\sum_{j}A_{j,p}D_{\ell,j}}.
\]

\end_inset

At optimimality of 
\begin_inset Formula $Q$
\end_inset

, we have
\begin_inset Formula 
\[
\mathcal{L}(A,D)=\mathcal{L}_{J}(A,D,\dot{Q})
\]

\end_inset


\begin_inset Formula 
\[
\nabla_{A}\mathcal{L}(A,D)=\nabla_{A}\mathcal{L}_{J}(A,D,\dot{Q})
\]

\end_inset


\begin_inset Formula 
\[
\nabla_{D}\mathcal{L}(A,D)=\nabla_{D}\mathcal{L}_{J}(A,D,\dot{Q})
\]

\end_inset


\end_layout

\begin_layout Subsection
Optimization
\end_layout

\begin_layout Standard
If we define 
\begin_inset Formula 
\[
\tilde{\phi}_{t,\gamma}\left(A^{t},A\right)=\phi\left(A^{t}\right)+\left\langle \nabla\phi\left(A^{t}\right),A-A^{t}\right\rangle +\gamma\left\Vert A-A^{t}\right\Vert _{F}^{2}
\]

\end_inset

Then we have
\begin_inset Formula 
\[
\phi\left(A^{t}\right)\le\tilde{\phi}_{t,\gamma}\left(A^{t},A\right)
\]

\end_inset


\end_layout

\begin_layout Standard
What is 
\begin_inset Formula $\gamma$
\end_inset

 here? The Lipschitz constant?
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\phi_{Q}\left(A,D\right)=\mathcal{L}_{J}\left(A,D,Q\right)$
\end_inset

, view as as a function of 
\begin_inset Formula $A,D$
\end_inset

.
 So we can minimize 
\begin_inset Formula $\mathcal{L}(A,D)$
\end_inset

 by solving a sequence of problem of the form
\begin_inset Formula 
\[
\min_{A,D}\lambda\psi\left(A\right)+\phi_{Q}\left(A,D\right)+\mathcal{I}\left(A\in\mathcal{S}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
So we can define a proximal step as
\begin_inset Formula 
\[
\min_{A}\tilde{\psi_{t}}\left(A^{t},A\right)+\tilde{\phi}_{Q}\left(A^{t},A,D\right)
\]

\end_inset


\end_layout

\begin_layout Standard
WE CAN DO LINESEARCH OVER GAMMA
\end_layout

\begin_layout Subsection
An algorithm?
\end_layout

\begin_layout Paragraph
Let us define our loss function as
\begin_inset Formula 
\begin{align*}
\mathcal{L}_{J}(A,D,Q) & :=-\sum_{p,\ell}\log\left(A_{\ell,p}\right)\sum_{i}X_{i,p}Q_{i,p,\ell}\\
 & -\sum_{\ell,i}\log\left(D_{\ell,i}\right)\sum_{p}X_{\ell,p}Q_{\ell,p,i}\\
 & +\sum_{\ell,p}\sum_{i}X_{\ell,p}Q_{\ell,p,i}\log\left(Q_{\ell,p,i}\right)\\
 & +\sum_{\ell,p}A_{\ell,p}\sum_{i}D_{i,\ell}\\
 & +\frac{\lambda}{2}\sum_{\ell,p}A_{\ell,p}\sum_{p_{2}}\Delta_{p,p_{2}}A_{\ell,p_{2}}
\end{align*}

\end_inset

A update: 
\end_layout

\begin_layout Quotation
The Lagrangian is given by 
\begin_inset Formula 
\[
\mathcal{D}_{J}(A,D,Q,\nu)=\mathcal{L}_{J}(A,D,Q)+\nu^{T}\left(A\mathbf{1}^{p}-\mathbf{1}^{k}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
A direct optimization with respec of 
\begin_inset Formula $A$
\end_inset

 is complicated because of the Laplacian.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left.\nabla_{A}\mathcal{D}_{J}(A,D^{t},Q)\right|_{\ell,p}=-\frac{\sum_{i}X_{i,p}Q_{i,p,\ell}^{t}}{A_{\ell,p}}+\sum_{i}D_{i,\ell}^{t}+\lambda\sum_{p_{2}}\Delta_{p,p_{2}}A_{\ell,p_{2}}+\nu_{p}=0
\]

\end_inset

So instead, we optimize an auxiliary function
\begin_inset Formula 
\begin{align*}
\tilde{\mathcal{D}_{J}}(A,A^{t},D^{t},Q^{t},\nu) & :=-\sum_{\ell,i}\log\left(D_{\ell,i}\right)\sum_{p}X_{\ell,p}Q_{\ell,p,i}-\sum_{\ell,i}\log\left(D_{\ell,i}\right)\sum_{p}X_{\ell,p}Q_{\ell,p,i}+\sum_{\ell,p}\sum_{i}X_{\ell,p}Q_{\ell,p,i}\log\left(Q_{\ell,p,i}\right)+\sum_{\ell,p}A_{\ell,p}\sum_{i}D_{i,\ell}\\
 & -\frac{\lambda}{2}\sum_{\ell}A_{\ell}^{tT}\Delta A_{\ell}^{t}+\lambda\sum_{\ell}A_{\ell}^{T}\Delta A_{\ell}^{t}+\sigma(\Delta)\frac{\lambda}{2}\|A-A^{t}\|_{F}^{2}\\
 & +\nu^{T}\left(A\mathbf{1}^{p}-\mathbf{1}^{k}\right)
\end{align*}

\end_inset

The gradient of the auxiliary function becomes
\begin_inset Formula 
\[
\left.\nabla_{A}\tilde{\mathcal{D}_{J}}(A,A^{t},D^{t},Q^{t},\nu)\right|_{\ell,p}=-\frac{\sum_{i}X_{i,p}Q_{i,p,\ell}^{t}}{A_{\ell,p}}+\sum_{i}D_{i,\ell}^{t}+\lambda\sum_{p_{2}}\Delta_{p,p_{2}}A_{\ell,p_{2}}^{t}+\lambda\sigma(\Delta)\left(A_{\ell,p}-A_{\ell,p}^{t}\right)+\nu_{p}=0
\]

\end_inset

Let us solve this equation assuming that 
\begin_inset Formula $A_{\ell,p}>0.$
\end_inset


\begin_inset Formula 
\[
\lambda\sigma(\Delta)A_{\ell,p}^{2}+A_{\ell,p}\left(\sum_{i}D_{i,\ell}^{t}+\lambda\sum_{p_{2}}\Delta_{p,p_{2}}A_{\ell,p_{2}}^{t}-A_{\ell,p}^{t}\lambda\sigma(\Delta)+\nu_{p}\right)-\sum_{i}X_{i,p}Q_{i,p,\ell}^{t}=0
\]

\end_inset

Let us define 
\begin_inset Formula $a=\lambda\sigma(\Delta)$
\end_inset

, 
\begin_inset Formula $b=\sum_{i}D_{i,\ell}^{t}+\lambda\sum_{p_{2}}\Delta_{p,p_{2}}A_{\ell,p_{2}}^{t}-A_{\ell,p}^{t}\lambda\sigma(\Delta)+\nu_{p}$
\end_inset

, and 
\begin_inset Formula $c=-\sum_{i}X_{i,p}Q_{i,p,\ell}^{t}$
\end_inset

.
 It is easy to see that 
\begin_inset Formula $a>0,c<0$
\end_inset

.
 So 
\begin_inset Formula $ac<0$
\end_inset

 and 
\begin_inset Formula 
\[
b^{2}-4ac>b^{2}>0
\]

\end_inset

Thus, we have two real solution, one negative and one positive.
 We are interested in the positive one:
\begin_inset Formula 
\[
A_{\ell,p}=\frac{-b+\sqrt{b^{2}-4ac}}{2a}
\]

\end_inset

Note that finding the right 
\begin_inset Formula $\nu$
\end_inset

 is probably harder as the function is not as nice as before.
 We have
\begin_inset Formula 
\begin{align*}
1 & =\sum_{p}A_{p}\\
 & =\sum_{p}-\frac{b_{p}\left(\nu_{p}\right)+\sqrt{b_{p}\left(\nu_{p}\right)^{2}-4ac_{p}}}{2a}\\
 & =\sum_{p}-\frac{s_{p}+\nu_{p}+\sqrt{\left(s_{p}+\nu_{p}\right)^{2}-4ac_{p}}}{2a}
\end{align*}

\end_inset

where 
\begin_inset Formula $s_{p}=\sum_{i}D_{i,\ell}^{t}+\lambda\sum_{p_{2}}\Delta_{p,p_{2}}A_{\ell,p_{2}}^{t}-A_{\ell,p}^{t}\lambda\sigma(\Delta)$
\end_inset

 
\end_layout

\begin_layout Standard
Check for a library for dicotomy...
\end_layout

\begin_layout Paragraph
D update:
\end_layout

\begin_layout Standard
We simply that the gradient
\end_layout

\begin_layout Paragraph
\begin_inset Formula 
\[
\left.\nabla_{D}\mathcal{D}_{J}(A^{t},D,Q^{t})\right|_{\ell,p}=-\frac{\sum_{i}X_{\ell,i}Q_{\ell,i,p}^{t}}{D_{\ell,p}}+\sum_{p}A_{p,i}^{t}=0
\]

\end_inset


\end_layout

\begin_layout Standard
The update rule becomes
\begin_inset Formula 
\[
D_{\ell,p}=\frac{\sum_{i}X_{\ell,i}Q_{\ell,i,p}^{t}}{\sum_{p}A_{p,i}^{t}}
\]

\end_inset

Alternatively, we need to take into account that 
\begin_inset Formula $D=GP$
\end_inset

.
 So we find
\begin_inset Formula 
\begin{align*}
\left.\nabla_{P}\mathcal{D}_{J}(A,P,Q)\right|_{c_{0},k_{0}} & :=\left.\nabla_{P}\left(-\sum_{\ell,k}\log\left(D_{\ell,k}\right)\sum_{p}X_{\ell,p}Q_{\ell,p,k}+\sum_{\ell,p}\sum_{k}A_{k,p}D_{\ell,k}\right)_{D=GP}\right|_{c_{0},k_{0}}\\
 & =\left.\nabla_{P}\left(-\sum_{\ell,k,p}\log\left(\sum_{c}G_{\ell,c}P_{c,k}\right)X_{\ell,p}Q_{\ell,p,k}+\sum_{\ell,p,c,k}A_{k,p}G_{\ell,c}P_{c,k}\right)\right|_{c_{0},k_{0}}\\
 & =-\sum_{\ell}\frac{G_{\ell,c_{0}}\sum_{p}X_{\ell,p}Q_{\ell,p,k_{0}}}{\sum_{c}G_{\ell,c}P_{c,k_{0}}}+\sum_{p,\ell}A_{k_{0},p}G_{\ell,c_{0}}
\end{align*}

\end_inset

In matrix notation, we find
\begin_inset Formula 
\[
\nabla_{P}\mathcal{D}_{J}(A,P,Q)=-G^{T}\left(\left[XQ\right]\oslash GP\right)+G^{T}1^{\ell,p}A^{T}
\]

\end_inset

where 
\begin_inset Formula $\left[XQ\right]_{\ell,k}=\sum_{p}X_{\ell,p}Q_{\ell,p,k}.$
\end_inset

This is a bit annoying, because come back to a multiplicative algorithm!
 I believe we have to live with this...
\begin_inset Formula 
\begin{align*}
P^{t+1} & =P^{t}-\gamma_{t}\nabla_{P}\mathcal{D}_{J}(A,P,Q)\\
 & =P^{t}-\gamma_{t}\left[-G^{T}\left(\left[XQ\right]\oslash GP\right)+G^{T}1^{\ell,p}A^{T}\right]\\
 & =P^{t}+\gamma_{t}\left[G^{T}\left(\left[XQ\right]\oslash GP\right)-G^{T}1^{\ell,p}A^{T}\right]\\
 & =\left(P^{t}\oslash G^{T}1^{\ell,p}A^{T}\right)\circ\left(G^{T}\left(\left[XQ\right]\oslash GP^{t}\right)\right)
\end{align*}

\end_inset

where the learning rate is set to
\begin_inset Formula 
\[
\gamma_{t}=P^{t}\oslash G^{T}1^{\ell,p}A^{T}
\]

\end_inset


\end_layout

\begin_layout Standard
Let us replace Q with its current value with respect of 
\begin_inset Formula $P,A$
\end_inset

.
 We have
\begin_inset Formula 
\begin{align*}
\left[XQ\right]_{\ell,k} & =\sum_{p}X_{\ell,p}Q_{\ell,p,k}\\
 & =\sum_{p}X_{\ell,p}\frac{A_{k,p}D_{\ell,k}}{\sum_{j}A_{j,p}D_{\ell,j}}\\
 & =D_{\ell,k}\sum_{p}A_{k,p}\frac{X_{\ell,p}}{\sum_{j}A_{j,p}D_{\ell,j}}\\
 & =\left[D\circ\left(\left(X\oslash DA\right)A^{T}\right)\right]_{\ell,k}
\end{align*}

\end_inset

Given that 
\begin_inset Formula $D=GP$
\end_inset

, we find
\begin_inset Formula 
\begin{align*}
P^{t+1} & =\left(P^{t}\oslash G^{T}1^{\ell,p}A^{T}\right)\circ\left(G^{T}\left(\left[XQ\right]\oslash GP^{t}\right)\right)\\
 & =\left(P^{t}\oslash G^{T}1^{\ell,p}A^{T}\right)\circ\left(G^{T}\left(GP^{t}\circ\left(\left(X\oslash GP^{t}A\right)A^{T}\right)\oslash GP^{t}\right)\right)\\
 & =\left(P^{t}\oslash G^{T}1^{\ell,p}A^{T}\right)\circ\left(G^{T}\left(X\oslash GP^{t}A\right)A^{T}\right)
\end{align*}

\end_inset

which is the same update as we had previously!!!
\end_layout

\begin_layout Paragraph
Q update:
\end_layout

\begin_layout Standard
We simply do 
\begin_inset Formula 
\[
Q_{\ell,p,k}=\frac{A_{k,p}^{t}D_{\ell,k}^{t}}{\sum_{j}A_{j,p}^{t}D_{\ell,j}^{t}}.
\]

\end_inset


\end_layout

\begin_layout Subsection
Definitions and stuff to know
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $f$
\end_inset

 be a differentiable and convex function.
 Then we have
\begin_inset Formula 
\[
f(x)=f(x_{t})+\left\langle \nabla f(x_{t}),x-x_{t}\right\rangle +D_{f}\left(x\|x_{t}\right)
\]

\end_inset

where 
\begin_inset Formula $D_{f}$
\end_inset

 is the Bregman divergence associated with 
\begin_inset Formula $f$
\end_inset

.
 This follows from the definition of the Bregmann divergence:
\begin_inset Formula 
\[
D_{f}\left(x\|x_{t}\right):=f(x)-f(x_{t})-\left\langle \nabla f(x_{t}),x-x_{t}\right\rangle .
\]

\end_inset

For example if 
\begin_inset Formula $f(x)=-\log(x),$
\end_inset

 then 
\begin_inset Formula 
\[
D_{f}\left(x\|x_{t}\right):=-\log\left(\frac{x}{x_{t}}\right)+\frac{x}{x_{t}}-1,
\]

\end_inset

which is the Itakuraâ€“Saito distance.
\end_layout

\begin_layout Subsection
A connection here
\end_layout

\begin_layout Standard
Question: can we just use 
\begin_inset Formula $\dot{Q}$
\end_inset

 and assume that it is equal to 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\mathcal{L}$
\end_inset

?
\end_layout

\begin_layout LyX-Code
\begin_inset Formula 
\[
\mathcal{L}_{J}(A,D^{t},Q^{t})=\mathcal{L}_{J}(A^{t},D^{t},Q^{t})+\left\langle \nabla_{A}\mathcal{L}_{J}(A^{t},D^{t},Q^{t}),A-A^{t}\right\rangle +D_{\mathcal{L}_{J}}\left(A\|A^{t}\right)
\]

\end_inset


\begin_inset Formula 
\begin{align*}
\left\langle \nabla_{A}\mathcal{L}_{J}(A^{t},D^{t},\dot{Q^{t}}),A-A^{t}\right\rangle  & =\sum_{\ell,p}\left(\sum_{i}D_{i,\ell}^{t}-\frac{\sum_{i}X_{i,p}\dot{Q_{i,p,\ell}^{t}}}{A_{\ell,p}^{t}}\right)\left(A_{\ell,p}-A_{\ell,p}^{t}\right)\\
\end{align*}

\end_inset


\end_layout

\end_body
\end_document
